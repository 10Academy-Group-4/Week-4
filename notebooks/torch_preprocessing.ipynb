{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "wDwR7JKg95qs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join('../modules')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_transcript import CleanTrans\n",
    "from pre_process import PrepSound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '../data/SWAHILI/data/train/wav'\n",
    "test_path = '../data/SWAHILI/data/test/wav5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dN9zi1hp1Iuj"
   },
   "outputs": [],
   "source": [
    "train_folders = os.listdir(train_path)\n",
    "test_folder = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGbew0iouAbT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oGbew0iouAbT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'specs_dict = {'waves':[], 'specs':[], 'sample_len':[], 'processed_len':[], 'smaple_rate':[]}\\nnum_i = 0\\nwhile num_i < 2000:\\n    for folder in train_folders:\\n        folder_path = train_path+'/'+folder\\n        for f in os.listdir(folder_path):\\n            if num_i < 2000:\\n                if f.endswith('.wav'):\\n                  prep = PrepSound(audio_file=f, path=folder_path)\\n                  prep_out = prep.pre_process(newsr=16000, max_ms=58400)\\n                  specs_dict['waves'].append(f[:-4])\\n                  specs_dict['specs'].append(prep_out['specs'])\\n                  specs_dict['sample_len'].append(prep_out['sample_len'])\\n                  specs_dict['processed_len'].append(prep_out['processed_len'])\\n                  specs_dict['smaple_rate'].append(prep_out['smaple_rate'])\\n                  num_i += 1\\n                else:\\n                    break\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''specs_dict = {'waves':[], 'specs':[], 'sample_len':[], 'processed_len':[], 'smaple_rate':[]}\n",
    "num_i = 0\n",
    "while num_i < 2000:\n",
    "    for folder in train_folders:\n",
    "        folder_path = train_path+'/'+folder\n",
    "        for f in os.listdir(folder_path):\n",
    "            if num_i < 2000:\n",
    "                if f.endswith('.wav'):\n",
    "                  prep = PrepSound(audio_file=f, path=folder_path)\n",
    "                  prep_out = prep.pre_process(newsr=16000, max_ms=58400)\n",
    "                  specs_dict['waves'].append(f[:-4])\n",
    "                  specs_dict['specs'].append(prep_out['specs'])\n",
    "                  specs_dict['sample_len'].append(prep_out['sample_len'])\n",
    "                  specs_dict['processed_len'].append(prep_out['processed_len'])\n",
    "                  specs_dict['smaple_rate'].append(prep_out['smaple_rate'])\n",
    "                  num_i += 1\n",
    "                else:\n",
    "                    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''specs_dict_all = {'waves':[], 'specs':[], 'sample_len':[], 'processed_len':[], 'smaple_rate':[]}\n",
    "for folder in train_folders:\n",
    "    folder_path = train_path+'/'+folder\n",
    "    for f in os.listdir(folder_path):\n",
    "        if f.endswith('.wav'):\n",
    "          prep = PrepSound(audio_file=f, path=folder_path)\n",
    "          prep_out = prep.pre_process(newsr=16000, max_ms=58400)\n",
    "          specs_dict_all['waves'].append(f[:-4])\n",
    "          specs_dict_all['specs'].append(prep_out['specs'])\n",
    "          specs_dict_all['sample_len'].append(prep_out['sample_len'])\n",
    "          specs_dict_all['processed_len'].append(prep_out['processed_len'])\n",
    "          specs_dict_all['smaple_rate'].append(prep_out['smaple_rate'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store',\n",
       " '._.DS_Store',\n",
       " 'SWH-05-20101124',\n",
       " 'SWH-05-20101211',\n",
       " 'SWH-05-20101222',\n",
       " 'SWH-15-20110203',\n",
       " 'SWH-15-20110311',\n",
       " 'SWH-15-20110323']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error loading audio file: failed to open file ../data/SWAHILI/data/test/wav5/SWH-05-20101124/._16k-emission_swahili_05h30_-_06h00_tu_20101124_part001g.wav",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-894807d2054d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mprep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrepSound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mprep_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewsr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m58400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0mtest_specs_dict_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'waves'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mtest_specs_dict_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'specs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/10ac-batch-4/all-notebooks/michael.da/Week-4/modules/pre_process.py\u001b[0m in \u001b[0;36mpre_process\u001b[0;34m(self, newsr, max_ms, top_db)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewsr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_db\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrechannel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_channel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m#self.trim_audio(trim_db=top_db, output=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/10ac-batch-4/all-notebooks/michael.da/Week-4/modules/pre_process.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maud_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filepath, frame_offset, num_frames, normalize, channels_first, format)\u001b[0m\n\u001b[1;32m    150\u001b[0m                 filepath, frame_offset, num_frames, normalize, channels_first, format)\n\u001b[1;32m    151\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     return torch.ops.torchaudio.sox_io_load_audio_file(\n\u001b[0m\u001b[1;32m    153\u001b[0m         filepath, frame_offset, num_frames, normalize, channels_first, format)\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error loading audio file: failed to open file ../data/SWAHILI/data/test/wav5/SWH-05-20101124/._16k-emission_swahili_05h30_-_06h00_tu_20101124_part001g.wav"
     ]
    }
   ],
   "source": [
    "\"\"\"test_specs_dict_all = {'waves':[], 'specs':[], 'sample_len':[], 'processed_len':[], 'smaple_rate':[]}\n",
    "for folder in test_folder[2:]:\n",
    "    folder_path = test_path+'/'+folder\n",
    "    for f in os.listdir(folder_path):\n",
    "        if f.endswith('.wav'):\n",
    "          prep = PrepSound(audio_file=f, path=folder_path)\n",
    "          prep_out = prep.pre_process(newsr=16000, max_ms=58400)\n",
    "          test_specs_dict_all['waves'].append(f[:-4])\n",
    "          test_specs_dict_all['specs'].append(prep_out['specs'])\n",
    "          test_specs_dict_all['sample_len'].append(prep_out['sample_len'])\n",
    "          test_specs_dict_all['processed_len'].append(prep_out['processed_len'])\n",
    "          test_specs_dict_all['smaple_rate'].append(prep_out['smaple_rate'])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test_specs_dict_all, open('../data/test_dict_all', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "oGbew0iouAbT"
   },
   "outputs": [],
   "source": [
    "#pickle.dump(specs_dict_all, open('../data/train_dict_all', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle.dump(specs_dict, open('../data/train_sample_dict', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dvIRG3V9-S8r"
   },
   "outputs": [],
   "source": [
    "train_text_path = '../data/SWAHILI/data/train/text'\n",
    "test_text_path = '../data/SWAHILI/data/test/text'\n",
    "transcript = pd.read_csv(train_text_path, sep='\\t', names=['file','transcript'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "feIzLLN3-6is",
    "outputId": "3c4afcd4-ffc4-498f-cad6-c55848149422"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part10'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript['file'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part100'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript['file'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_transcript import CleanTrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = CleanTrans(df=transcript, trans_col='transcript')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_clean = clean.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10105</th>\n",
       "      <td>SWH-15-20110310_16k-emission_swahili_15h00_-_1...</td>\n",
       "      <td>na somo lile lililopokelewa kule kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10106</th>\n",
       "      <td>SWH-15-20110310_16k-emission_swahili_15h00_-_1...</td>\n",
       "      <td>ambapo mtu aliyeshindwa kwenye uchaguzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10107</th>\n",
       "      <td>SWH-15-20110310_16k-emission_swahili_15h00_-_1...</td>\n",
       "      <td>ni kauli yake mchambuzi wa masuala ya siasa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10108</th>\n",
       "      <td>SWH-15-20110310_16k-emission_swahili_15h00_-_1...</td>\n",
       "      <td>mwanasheria anayemtetea rais wa zamani wa liberia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10109</th>\n",
       "      <td>SWH-15-20110310_16k-emission_swahili_15h00_-_1...</td>\n",
       "      <td>na kesi yake ya kubadilishana almasi na silaha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10110 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    file  \\\n",
       "0      SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "1      SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "2      SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "3      SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "4      SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "...                                                  ...   \n",
       "10105  SWH-15-20110310_16k-emission_swahili_15h00_-_1...   \n",
       "10106  SWH-15-20110310_16k-emission_swahili_15h00_-_1...   \n",
       "10107  SWH-15-20110310_16k-emission_swahili_15h00_-_1...   \n",
       "10108  SWH-15-20110310_16k-emission_swahili_15h00_-_1...   \n",
       "10109  SWH-15-20110310_16k-emission_swahili_15h00_-_1...   \n",
       "\n",
       "                                              transcript  \n",
       "0                 rais wa tanzania jakaya mrisho kikwete  \n",
       "1      yanayo andaliwa nami pendo pondo idhaa ya kisw...  \n",
       "2      inayokutangazia moja kwa moja kutoka jijini da...  \n",
       "3      juma hili bara la afrika limeshuhudia raia wa ...  \n",
       "4        wakipiga kura ya maoni ilikufanya mabadiliko ya  \n",
       "...                                                  ...  \n",
       "10105             na somo lile lililopokelewa kule kenya  \n",
       "10106            ambapo mtu aliyeshindwa kwenye uchaguzi  \n",
       "10107        ni kauli yake mchambuzi wa masuala ya siasa  \n",
       "10108  mwanasheria anayemtetea rais wa zamani wa liberia  \n",
       "10109  na kesi yake ya kubadilishana almasi na silaha...  \n",
       "\n",
       "[10110 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs_dict_l = pickle.load(open('../data/train_sample_dict', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenize_text import TokenizerText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_list = [t.split(' ') for t in transcript_clean['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = TokenizerText(texts=transcript_clean['transcript'],padding='pre',filters=None, reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens=[tokenize.text_to_tokens(text=t, reverse=False, padding=True) for t in transcript_clean['transcript']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_clean['tokens'] = tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict_df = pd.DataFrame(specs_dict_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>waves</th>\n",
       "      <th>specs</th>\n",
       "      <th>sample_len</th>\n",
       "      <th>processed_len</th>\n",
       "      <th>smaple_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>[[[tensor(-24.5810), tensor(-24.5810), tensor(...</td>\n",
       "      <td>50240</td>\n",
       "      <td>934400</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>[[[tensor(-26.9436), tensor(-26.9436), tensor(...</td>\n",
       "      <td>49600</td>\n",
       "      <td>934400</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>[[[tensor(-24.4068), tensor(-24.4068), tensor(...</td>\n",
       "      <td>58400</td>\n",
       "      <td>934400</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>[[[tensor(-23.7175), tensor(-23.7175), tensor(...</td>\n",
       "      <td>62400</td>\n",
       "      <td>934400</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SWH-05-20101106_16k-emission_swahili_05h30_-_0...</td>\n",
       "      <td>[[[tensor(-26.2334), tensor(-26.2334), tensor(...</td>\n",
       "      <td>47040</td>\n",
       "      <td>934400</td>\n",
       "      <td>16000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               waves  \\\n",
       "0  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "1  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "2  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "3  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "4  SWH-05-20101106_16k-emission_swahili_05h30_-_0...   \n",
       "\n",
       "                                               specs  sample_len  \\\n",
       "0  [[[tensor(-24.5810), tensor(-24.5810), tensor(...       50240   \n",
       "1  [[[tensor(-26.9436), tensor(-26.9436), tensor(...       49600   \n",
       "2  [[[tensor(-24.4068), tensor(-24.4068), tensor(...       58400   \n",
       "3  [[[tensor(-23.7175), tensor(-23.7175), tensor(...       62400   \n",
       "4  [[[tensor(-26.2334), tensor(-26.2334), tensor(...       47040   \n",
       "\n",
       "   processed_len  smaple_rate  \n",
       "0         934400        16000  \n",
       "1         934400        16000  \n",
       "2         934400        16000  \n",
       "3         934400        16000  \n",
       "4         934400        16000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spec_dict_df['waves'] == \n",
    "transcript_clean['file'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SWH-05-20101106_16k-emission_swahili_05h30_-_06h00_tu_20101106_part103'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_dict_df['waves'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = spec_dict_df.merge(transcript_clean, left_on='waves', right_on='file', how='inner')\n",
    "train_df.drop(columns='file', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['waves'][5] == train_df['waves'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rais wa tanzania jakaya mrisho kikwete</td>\n",
       "      <td>[[17, 1, 3, 13, 2, 9, 1, 2, 12, 1, 4, 18, 1, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yanayo andaliwa nami pendo pondo idhaa ya kisw...</td>\n",
       "      <td>[[15, 1, 4, 1, 15, 10, 2, 1, 4, 19, 1, 14, 3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inayokutangazia moja kwa moja kutoka jijini da...</td>\n",
       "      <td>[[3, 4, 1, 15, 10, 5, 6, 12, 1, 4, 20, 1, 18, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juma hili bara la afrika limeshuhudia raia wa ...</td>\n",
       "      <td>[[21, 6, 7, 1, 2, 11, 3, 14, 3, 2, 16, 1, 17, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wakipiga kura ya maoni ilikufanya mabadiliko ya</td>\n",
       "      <td>[[9, 1, 5, 3, 23, 3, 20, 1, 2, 5, 6, 17, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>timu kama red berates pia ilikuwa hivyo hivyo</td>\n",
       "      <td>[[12, 3, 7, 6, 2, 5, 1, 7, 1, 2, 17, 8, 19, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>ilikuwa na ile hali ya kuchanganya changanya w...</td>\n",
       "      <td>[[3, 14, 3, 5, 6, 9, 1, 2, 4, 1, 2, 3, 14, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>hiyo ndio pia ilikuja ikachangia wakakuja waka...</td>\n",
       "      <td>[[11, 3, 15, 10, 2, 4, 19, 3, 10, 2, 23, 3, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>unajua sasa ikifika pale katikati sasa hapo nd...</td>\n",
       "      <td>[[6, 4, 1, 21, 6, 1, 2, 13, 1, 13, 1, 2, 3, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>na jeshi la polisi la cote de voire lasema ata...</td>\n",
       "      <td>[[4, 1, 2, 21, 8, 13, 11, 3, 2, 14, 1, 2, 23, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1977 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript  \\\n",
       "0                rais wa tanzania jakaya mrisho kikwete   \n",
       "1     yanayo andaliwa nami pendo pondo idhaa ya kisw...   \n",
       "2     inayokutangazia moja kwa moja kutoka jijini da...   \n",
       "3     juma hili bara la afrika limeshuhudia raia wa ...   \n",
       "4       wakipiga kura ya maoni ilikufanya mabadiliko ya   \n",
       "...                                                 ...   \n",
       "1972      timu kama red berates pia ilikuwa hivyo hivyo   \n",
       "1973  ilikuwa na ile hali ya kuchanganya changanya w...   \n",
       "1974  hiyo ndio pia ilikuja ikachangia wakakuja waka...   \n",
       "1975  unajua sasa ikifika pale katikati sasa hapo nd...   \n",
       "1976  na jeshi la polisi la cote de voire lasema ata...   \n",
       "\n",
       "                                                 tokens  \n",
       "0     [[17, 1, 3, 13, 2, 9, 1, 2, 12, 1, 4, 18, 1, 4...  \n",
       "1     [[15, 1, 4, 1, 15, 10, 2, 1, 4, 19, 1, 14, 3, ...  \n",
       "2     [[3, 4, 1, 15, 10, 5, 6, 12, 1, 4, 20, 1, 18, ...  \n",
       "3     [[21, 6, 7, 1, 2, 11, 3, 14, 3, 2, 16, 1, 17, ...  \n",
       "4     [[9, 1, 5, 3, 23, 3, 20, 1, 2, 5, 6, 17, 1, 2,...  \n",
       "...                                                 ...  \n",
       "1972  [[12, 3, 7, 6, 2, 5, 1, 7, 1, 2, 17, 8, 19, 2,...  \n",
       "1973  [[3, 14, 3, 5, 6, 9, 1, 2, 4, 1, 2, 3, 14, 8, ...  \n",
       "1974  [[11, 3, 15, 10, 2, 4, 19, 3, 10, 2, 23, 3, 1,...  \n",
       "1975  [[6, 4, 1, 21, 6, 1, 2, 13, 1, 13, 1, 2, 3, 5,...  \n",
       "1976  [[4, 1, 2, 21, 8, 13, 11, 3, 2, 14, 1, 2, 23, ...  \n",
       "\n",
       "[1977 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['transcript', 'tokens']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCG7lSWpikjz"
   },
   "source": [
    "##**Load audio file**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "bP9ojedwiuHL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10110"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transcript_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = tokenize.text_to_tokens(text='andaliwa andaliwa')\n",
    "tex = tokenize.tokens_to_string(tokens=arr)\n",
    "alph = tokenize.token_to_word(token=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJ3udaAotjHQ"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE5amNUJivnz"
   },
   "source": [
    "##**Load transcriptions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nADL4Zvi7mH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDP0Hw7di8Ea"
   },
   "source": [
    "##**Convert into channels** \n",
    "Some of the sound files are mono (ie. 1 audio channel) while most of them are stereo (ie. 2 audio channels). Since the Neural network model expects all items to have the same dimensions, we will convert the mono files to stereo, by duplicating the first channel to the second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eclp7dxDjVzE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_NjiB1XjXQK"
   },
   "source": [
    "##**Standardize sampling rate**\n",
    "We must standardize and convert all audio to the same sampling rate so that all arrays have the same dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mzKKGaWKjpsr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYsGZ7kPjrT3"
   },
   "source": [
    "##**Resize to the same length**\n",
    "Resize to get an equal-sized audio sample by extending duration by padding it with silence, or by truncating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znnWj4IokMRx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCRK-RobkN3i"
   },
   "source": [
    "##**Data argumentation**\n",
    "Perform data augmentation on the raw audio signal by applying a Time Shift to shift the audio to the left or the right by a random amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VsCJMa7Kkm_I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En16rWXzkneV"
   },
   "source": [
    "##**Feature extraction**: \n",
    "Speech recognition methods derive features from the audio, such as Spectrogram or Mel Frequency Cepstrum (MFCC).\n",
    "\n",
    "* Convert the augmented audio to a Mel Spectrogram.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41z2AiSYleGx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCyl8e_olgLh"
   },
   "source": [
    "**Acoustic modeling:** \n",
    "\n",
    "After features are extracted, these vectors are passed to acoustic models. An acoustic model attempts to map the audio signal to the basic units of speech such as phonemes or graphemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3kBtRP8lsQA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJyV7EWznPsb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNbfzfZhb0ZGzfR0VpOkOwD",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1EamfpV5v6bteYcknWwAQvO2Fai29Xk2e",
   "name": "torch_preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
