{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "import pandas as pd\r\n",
    "import traceback\r\n",
    "import os,sys\r\n",
    "\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from MetaCreate import MetaCreate\r\n",
    "from AudioManipulator import AudioManipulator\r\n",
    "from preprocess_uitls import pad_audio_files, featurize\r\n",
    "from utils import char_map,index_map, int_sequence_to_text ,text_to_int_sequence\r\n",
    "\r\n",
    "\r\n",
    "import librosa\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\r\n",
    "\r\n",
    "    \r\n",
    "# from keras.utils.vis_utils import plot_model\r\n",
    "\r\n",
    "\r\n",
    "import _pickle as pickle\r\n",
    "from numpy.lib.stride_tricks import as_strided\r\n",
    "\r\n",
    "from Models import cnn_rnn_model,simple_rnn,model_2,bidirectional_rnn_model_gpu,bidirectional_rnn_model\r\n",
    "# from keras.callbacks import ModelCheckpoint   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import mlflow\r\n",
    "import mlflow.tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "data=pd.read_json('../artifacts/meta.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10179"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "data.drop(data[data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9357"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "with open('../artifacts/features.pkl','rb') as tel:\r\n",
    "    features=pickle.load(tel)\r\n",
    "    tel.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(len(features),len(data.text.to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9357 9357\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "valid_data=pd.read_json(\"../artifacts/valid_meta.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "valid_data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "valid_data.drop(valid_data[valid_data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "valid_data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "with open('../artifacts/valid_features.pkl','rb') as val:\r\n",
    "    valid_features=pickle.load(val)\r\n",
    "    val.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "print(len(valid_features),len(valid_data.text.to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1990 1990\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from Batch import Batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "\r\n",
    "MODEL_NAME = \"bidirectional_rnn_gpu\"\r\n",
    "EPOCHS=50\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bidirectional RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "bidirectional_rnn_gpu=bidirectional_rnn_model_gpu(input_dim=26, \r\n",
    "                        units=250)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 500)         417000    \n",
      "_________________________________________________________________\n",
      "norm_bidir_rnn (BatchNormali (None, None, 500)         2000      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 29)          14529     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 433,529\n",
      "Trainable params: 432,529\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from Train import train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Bidirectional RNN GPU\")\r\n",
    "train(audio_gen, input_to_softmax=bidirectional_rnn_gpu, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/10 08:06:27 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c06cf7e2747a45a98030c12a3b0e0f41', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "37/37 [==============================] - 51s 824ms/step - loss: 183.6048 - val_loss: 229.5184\n",
      "Epoch 2/50\n",
      "37/37 [==============================] - 28s 750ms/step - loss: 139.3651 - val_loss: 234.0773\n",
      "Epoch 3/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 134.1298 - val_loss: 206.2278\n",
      "Epoch 4/50\n",
      "37/37 [==============================] - 28s 757ms/step - loss: 130.5624 - val_loss: 170.3765\n",
      "Epoch 5/50\n",
      "37/37 [==============================] - 28s 750ms/step - loss: 127.9668 - val_loss: 156.5076\n",
      "Epoch 6/50\n",
      "37/37 [==============================] - 27s 746ms/step - loss: 125.6403 - val_loss: 140.2581\n",
      "Epoch 7/50\n",
      "37/37 [==============================] - 28s 763ms/step - loss: 124.9986 - val_loss: 147.2280\n",
      "Epoch 8/50\n",
      "37/37 [==============================] - 28s 747ms/step - loss: 123.7347 - val_loss: 138.5409\n",
      "Epoch 9/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 122.8607 - val_loss: 136.5978\n",
      "Epoch 10/50\n",
      "37/37 [==============================] - 27s 743ms/step - loss: 122.0354 - val_loss: 134.0776\n",
      "Epoch 11/50\n",
      "37/37 [==============================] - 28s 747ms/step - loss: 121.1214 - val_loss: 132.4346\n",
      "Epoch 12/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 120.6525 - val_loss: 126.8386\n",
      "Epoch 13/50\n",
      "37/37 [==============================] - 28s 747ms/step - loss: 120.5305 - val_loss: 137.0432\n",
      "Epoch 14/50\n",
      "37/37 [==============================] - 27s 746ms/step - loss: 119.9490 - val_loss: 130.4619\n",
      "Epoch 15/50\n",
      "37/37 [==============================] - 27s 742ms/step - loss: 120.7934 - val_loss: 125.3935\n",
      "Epoch 16/50\n",
      "37/37 [==============================] - 28s 751ms/step - loss: 119.7735 - val_loss: 125.7763\n",
      "Epoch 17/50\n",
      "37/37 [==============================] - 27s 741ms/step - loss: 119.2342 - val_loss: 127.7565\n",
      "Epoch 18/50\n",
      "37/37 [==============================] - 28s 748ms/step - loss: 118.5953 - val_loss: 128.5361\n",
      "Epoch 19/50\n",
      "37/37 [==============================] - 28s 751ms/step - loss: 118.4268 - val_loss: 124.9721\n",
      "Epoch 20/50\n",
      "37/37 [==============================] - 28s 755ms/step - loss: 118.4060 - val_loss: 128.4422\n",
      "Epoch 21/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 117.7026 - val_loss: 126.8698\n",
      "Epoch 22/50\n",
      "37/37 [==============================] - 27s 740ms/step - loss: 117.9054 - val_loss: 129.2223\n",
      "Epoch 23/50\n",
      "37/37 [==============================] - 27s 743ms/step - loss: 117.7173 - val_loss: 129.0522\n",
      "Epoch 24/50\n",
      "37/37 [==============================] - 27s 746ms/step - loss: 118.7884 - val_loss: 125.3983\n",
      "Epoch 25/50\n",
      "37/37 [==============================] - 28s 753ms/step - loss: 117.8391 - val_loss: 123.6073\n",
      "Epoch 26/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 118.0880 - val_loss: 132.5752\n",
      "Epoch 27/50\n",
      "37/37 [==============================] - 27s 742ms/step - loss: 118.5078 - val_loss: 124.2522\n",
      "Epoch 28/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 118.0249 - val_loss: 125.3059\n",
      "Epoch 29/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 117.5871 - val_loss: 128.4650\n",
      "Epoch 30/50\n",
      "37/37 [==============================] - 28s 747ms/step - loss: 117.9841 - val_loss: 128.0114\n",
      "Epoch 31/50\n",
      "37/37 [==============================] - 27s 744ms/step - loss: 117.7648 - val_loss: 128.6696\n",
      "Epoch 32/50\n",
      "37/37 [==============================] - 28s 748ms/step - loss: 117.8206 - val_loss: 124.9431\n",
      "Epoch 33/50\n",
      "37/37 [==============================] - 28s 750ms/step - loss: 117.6036 - val_loss: 131.1924\n",
      "Epoch 34/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 118.2565 - val_loss: 129.1235\n",
      "Epoch 35/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 117.7983 - val_loss: 124.9040\n",
      "Epoch 36/50\n",
      "37/37 [==============================] - 27s 745ms/step - loss: 118.1207 - val_loss: 129.1603\n",
      "Epoch 37/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 118.1302 - val_loss: 129.4966\n",
      "Epoch 38/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 117.8447 - val_loss: 128.4565\n",
      "Epoch 39/50\n",
      "37/37 [==============================] - 28s 748ms/step - loss: 118.0278 - val_loss: 121.0008\n",
      "Epoch 40/50\n",
      "37/37 [==============================] - 28s 746ms/step - loss: 118.1417 - val_loss: 131.1729\n",
      "Epoch 41/50\n",
      "37/37 [==============================] - 27s 743ms/step - loss: 118.4733 - val_loss: 129.8021\n",
      "Epoch 42/50\n",
      "37/37 [==============================] - 27s 744ms/step - loss: 118.3263 - val_loss: 125.1000\n",
      "Epoch 43/50\n",
      "37/37 [==============================] - 31s 840ms/step - loss: 117.4250 - val_loss: 130.7064\n",
      "Epoch 44/50\n",
      "37/37 [==============================] - 28s 762ms/step - loss: 117.5860 - val_loss: 138.3717\n",
      "Epoch 45/50\n",
      "37/37 [==============================] - 28s 764ms/step - loss: 118.1169 - val_loss: 122.7305\n",
      "Epoch 46/50\n",
      "37/37 [==============================] - 28s 764ms/step - loss: 117.7058 - val_loss: 136.2874\n",
      "Epoch 47/50\n",
      "37/37 [==============================] - 31s 830ms/step - loss: 117.7384 - val_loss: 131.8915\n",
      "Epoch 48/50\n",
      "37/37 [==============================] - 28s 773ms/step - loss: 117.9516 - val_loss: 135.8649\n",
      "Epoch 49/50\n",
      "37/37 [==============================] - 30s 805ms/step - loss: 118.2606 - val_loss: 132.6527\n",
      "Epoch 50/50\n",
      "37/37 [==============================] - 29s 781ms/step - loss: 117.4236 - val_loss: 127.3560\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/10 08:30:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "\r\n",
    "MODEL_NAME = \"simple_rnn\"\r\n",
    "EPOCHS=10\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "simple_rnn_model = simple_rnn(input_dim=26,\r\n",
    "                units=5,\r\n",
    "                activation='tanh',\r\n",
    "                output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, None, 5)           495       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 5)           20        \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 29)          174       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 679\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Simple RNN\")\r\n",
    "train(audio_gen, input_to_softmax=simple_rnn_model, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/09 14:35:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '822ca4f8a42f49e6a9915585f0ca1177', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 28s 661ms/step - loss: 207.9806 - val_loss: 223.8220\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 25s 672ms/step - loss: 172.3360 - val_loss: 226.4976\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 34s 916ms/step - loss: 172.2853 - val_loss: 199.5817\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 25s 677ms/step - loss: 171.7939 - val_loss: 196.6637\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 23s 629ms/step - loss: 172.3429 - val_loss: 198.5662\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 24s 642ms/step - loss: 172.3947 - val_loss: 180.0471\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 23s 632ms/step - loss: 172.1374 - val_loss: 174.4812\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 26s 695ms/step - loss: 171.5404 - val_loss: 174.9494\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 22s 593ms/step - loss: 171.3645 - val_loss: 161.4830\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 25s 675ms/step - loss: 171.2586 - val_loss: 168.6655\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/09 14:39:31 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "cnn_rnn = cnn_rnn_model(input_dim=26, # change to 13 if you would like to use MFCC features\r\n",
    "                        filters=250,\r\n",
    "                        kernel_size=4, \r\n",
    "                        conv_stride=1,\r\n",
    "                        conv_border_mode='same',\r\n",
    "                        units=200,output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 250)         26250     \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, None, 200)         90200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 29)          5829      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 124,079\n",
      "Trainable params: 123,179\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "\r\n",
    "MODEL_NAME = \"cnn_rnn\"\r\n",
    "EPOCHS=50\r\n",
    "MINI_BATCH_SIZE = 200\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"CNN RNN\")\r\n",
    "train(audio_gen, input_to_softmax=cnn_rnn, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/10 10:36:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '022c17e977e64e369982a259aa024365', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "46/46 [==============================] - 102s 870ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "46/46 [==============================] - 34s 747ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "25/46 [===============>..............] - ETA: 16s - loss: nan"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Speech"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "deep_speech = model_2(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='tanh',\r\n",
    "                dropout_rate=0.2,\r\n",
    "                number_of_layers=2,\r\n",
    "                output_dim=len(char_map)+1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 100)         10500     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "rnn_1 (GRU)                  (None, None, 250)         264000    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "final_layer_of_rnn (GRU)     (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_final (BatchNormaliza (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          7279      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 660,679\n",
      "Trainable params: 659,479\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "\r\n",
    "MODEL_NAME = \"deep_speech\"\r\n",
    "EPOCHS=200\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Deep Speech\")\r\n",
    "train(audio_gen, input_to_softmax=deep_speech, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/10 01:31:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '358e2b61010343d8afcb58844fc80bc2', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/200\n",
      "37/37 [==============================] - 68s 1s/step - loss: 221.2112 - val_loss: 226.1199\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 32s 869ms/step - loss: 167.7959 - val_loss: 170.9646\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 36s 964ms/step - loss: 137.1097 - val_loss: 133.5363\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 31s 847ms/step - loss: 117.7491 - val_loss: 128.7209\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 35s 965ms/step - loss: 108.3966 - val_loss: 111.8907\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 32s 863ms/step - loss: 101.9971 - val_loss: 107.1758\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 33s 882ms/step - loss: 97.3106 - val_loss: 99.3448\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 34s 922ms/step - loss: 93.6979 - val_loss: 95.0559\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 32s 877ms/step - loss: 90.7185 - val_loss: 93.2330\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 37s 1s/step - loss: 87.8700 - val_loss: 92.7505\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 36s 980ms/step - loss: 85.4679 - val_loss: 87.7966\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 36s 984ms/step - loss: 83.6344 - val_loss: 86.5012\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 34s 919ms/step - loss: 81.7365 - val_loss: 88.1438\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 32s 870ms/step - loss: 80.1245 - val_loss: 87.4478\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 32s 862ms/step - loss: 78.3952 - val_loss: 84.7619\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 34s 931ms/step - loss: 76.9113 - val_loss: 83.8808\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 34s 910ms/step - loss: 75.2864 - val_loss: 83.8863\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 33s 899ms/step - loss: 74.2721 - val_loss: 79.4457\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 34s 924ms/step - loss: 72.9639 - val_loss: 81.9762\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 33s 891ms/step - loss: 71.8181 - val_loss: 80.9188\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 34s 912ms/step - loss: 70.3802 - val_loss: 78.4532\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 33s 897ms/step - loss: 69.2124 - val_loss: 81.1352\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 32s 863ms/step - loss: 68.5789 - val_loss: 80.0317\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 31s 837ms/step - loss: 67.8060 - val_loss: 78.9715\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 33s 886ms/step - loss: 66.8214 - val_loss: 79.4713\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 34s 936ms/step - loss: 65.7407 - val_loss: 80.2314\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 33s 890ms/step - loss: 64.5911 - val_loss: 79.0377\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 35s 939ms/step - loss: 64.2717 - val_loss: 79.8015\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 37s 1s/step - loss: 63.3493 - val_loss: 79.1744\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 31s 842ms/step - loss: 62.4893 - val_loss: 75.7365\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 33s 881ms/step - loss: 61.8353 - val_loss: 80.9796\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 32s 870ms/step - loss: 60.9084 - val_loss: 79.2287\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 34s 927ms/step - loss: 60.3903 - val_loss: 79.5687\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 33s 900ms/step - loss: 59.9210 - val_loss: 83.1097\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 32s 857ms/step - loss: 58.9291 - val_loss: 82.1800\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 35s 964ms/step - loss: 58.3510 - val_loss: 79.2301\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 33s 904ms/step - loss: 57.7945 - val_loss: 79.1581\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 34s 932ms/step - loss: 57.6372 - val_loss: 79.2812\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 32s 873ms/step - loss: 56.8044 - val_loss: 80.5258\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 35s 952ms/step - loss: 56.4325 - val_loss: 82.3996\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 33s 899ms/step - loss: 55.9154 - val_loss: 81.1256\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 34s 923ms/step - loss: 55.2927 - val_loss: 84.1748\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 37s 993ms/step - loss: 54.9398 - val_loss: 84.5221\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 36s 984ms/step - loss: 54.3626 - val_loss: 83.4095\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 36s 978ms/step - loss: 53.8351 - val_loss: 84.1143\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 32s 872ms/step - loss: 53.1170 - val_loss: 88.1236\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 34s 919ms/step - loss: 52.7388 - val_loss: 82.5490\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 34s 909ms/step - loss: 52.7382 - val_loss: 81.1290\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 31s 853ms/step - loss: 52.1312 - val_loss: 83.9722\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 30s 823ms/step - loss: 51.6759 - val_loss: 83.0653\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 36s 965ms/step - loss: 51.3312 - val_loss: 81.8002\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 33s 886ms/step - loss: 50.8999 - val_loss: 83.2733\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 32s 855ms/step - loss: 50.5658 - val_loss: 82.6223\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 35s 942ms/step - loss: 50.0380 - val_loss: 82.3130\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 34s 925ms/step - loss: 49.6389 - val_loss: 82.8866\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 36s 969ms/step - loss: 49.7404 - val_loss: 87.1132\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 32s 868ms/step - loss: 48.8782 - val_loss: 85.2840\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 35s 962ms/step - loss: 48.4744 - val_loss: 84.8811\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 35s 938ms/step - loss: 48.5820 - val_loss: 82.1776\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 34s 917ms/step - loss: 48.3875 - val_loss: 89.8642\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 33s 894ms/step - loss: 47.6710 - val_loss: 85.8445\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 33s 898ms/step - loss: 47.5072 - val_loss: 84.3043\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 34s 937ms/step - loss: 46.6894 - val_loss: 87.1294\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 34s 912ms/step - loss: 46.8554 - val_loss: 89.0344\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 34s 933ms/step - loss: 46.5660 - val_loss: 84.6247\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 31s 845ms/step - loss: 46.0990 - val_loss: 86.5364\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 31s 849ms/step - loss: 46.1579 - val_loss: 87.8870\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 29s 799ms/step - loss: 45.7006 - val_loss: 87.7763\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 29s 797ms/step - loss: 45.6122 - val_loss: 85.8792\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 30s 801ms/step - loss: 45.4552 - val_loss: 91.7380\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 30s 803ms/step - loss: 44.8665 - val_loss: 87.9060\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 29s 799ms/step - loss: 44.7792 - val_loss: 84.4651\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 44.2429 - val_loss: 87.6195\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 29s 794ms/step - loss: 44.3839 - val_loss: 89.4389\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 30s 811ms/step - loss: 44.0665 - val_loss: 87.4677\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 30s 804ms/step - loss: 43.8637 - val_loss: 85.7717\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 32s 880ms/step - loss: 43.4390 - val_loss: 86.8783\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 31s 850ms/step - loss: 43.3916 - val_loss: 85.7915\n",
      "Epoch 79/200\n",
      " 8/37 [=====>........................] - ETA: 22s - loss: 44.8985"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-5c15dde94060>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautolog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Deep Speech\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_to_softmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep_speech\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMINI_BATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\same\\Documents\\10Acadamy\\Week 4\\System\\Week-4\\scripts\\Train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(audio_gen, input_to_softmax, model_name, minibatch_size, optimizer, epochs, verbose)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     hist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m          verbose=verbose)\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1941\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1943\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36msafe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpatch_is_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# the original implementation exception once the callback completes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_patch_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanaged_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_mlflow_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_managed_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 result = super(PatchWithManagedRun, self)._patch_implementation(\n\u001b[0m\u001b[0;32m    219\u001b[0m                     \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0m_log_early_stop_callback_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                 \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                 \u001b[0mdisable_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreroute_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                             ):\n\u001b[1;32m--> 448\u001b[1;33m                                 \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mog_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mog_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                             try_log_autologging_event(\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# WER"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "with open('models/simple_rnn_model.pickle', 'rb') as f:\r\n",
    "        simple_rnn_hist=pickle.load( f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "# simple_rnn_model.load_weights(simple_rnn_hist)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "import importlib"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "import wer"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "import Train\r\n",
    "importlib.reload(Train)\r\n",
    "from Train import  train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "import utils"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "importlib.reload(utils)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'utils' from 'd:\\\\same\\\\Documents\\\\10Acadamy\\\\Week 4\\\\System\\\\Week-4\\\\scripts\\\\utils.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "source": [
    "importlib.reload(wer)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'wer' from 'd:\\\\same\\\\Documents\\\\10Acadamy\\\\Week 4\\\\System\\\\Week-4\\\\scripts\\\\wer.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 197
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "source": [
    "from utils import  char_map,index_map,int_sequence_to_text,text_to_int_sequence"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "char_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '<SPACE>': 1,\n",
       " 'a': 2,\n",
       " 'b': 3,\n",
       " 'c': 4,\n",
       " 'd': 5,\n",
       " 'e': 6,\n",
       " 'f': 7,\n",
       " 'g': 8,\n",
       " 'h': 9,\n",
       " 'i': 10,\n",
       " 'j': 11,\n",
       " 'k': 12,\n",
       " 'l': 13,\n",
       " 'm': 14,\n",
       " 'n': 15,\n",
       " 'o': 16,\n",
       " 'p': 17,\n",
       " 'q': 18,\n",
       " 'r': 19,\n",
       " 's': 20,\n",
       " 't': 21,\n",
       " 'u': 22,\n",
       " 'v': 23,\n",
       " 'w': 24,\n",
       " 'x': 25,\n",
       " 'y': 26,\n",
       " 'z': 27}"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "source": [
    "index_map"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{0: '',\n",
       " 1: '<SPACE>',\n",
       " 2: 'a',\n",
       " 3: 'b',\n",
       " 4: 'c',\n",
       " 5: 'd',\n",
       " 6: 'e',\n",
       " 7: 'f',\n",
       " 8: 'g',\n",
       " 9: 'h',\n",
       " 10: 'i',\n",
       " 11: 'j',\n",
       " 12: 'k',\n",
       " 13: 'l',\n",
       " 14: 'm',\n",
       " 15: 'n',\n",
       " 16: 'o',\n",
       " 17: 'p',\n",
       " 18: 'q',\n",
       " 19: 'r',\n",
       " 20: 's',\n",
       " 21: 't',\n",
       " 22: 'u',\n",
       " 23: 'v',\n",
       " 24: 'w',\n",
       " 25: 'x',\n",
       " 26: 'y',\n",
       " 27: 'z'}"
      ]
     },
     "metadata": {},
     "execution_count": 133
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "source": [
    "text_to_int_sequence(\"z\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "reliad\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[27]"
      ]
     },
     "metadata": {},
     "execution_count": 218
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "int_sequence_to_text([28, 0])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['z']"
      ]
     },
     "metadata": {},
     "execution_count": 216
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "from wer import predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict(audio_gen,17,'validation',deep_speech)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "Error",
     "evalue": "Kernel is dead",
     "traceback": [
      "Error: Kernel is dead",
      "at g._sendKernelShellControl (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:52:852667)",
      "at g.sendShellMessage (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:52:852436)",
      "at g.requestExecute (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:52:854978)",
      "at d.requestExecute (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:37:304068)",
      "at w.requestExecute (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:24:122363)",
      "at w.executeCodeCell (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:90:324905)",
      "at w.execute (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:90:324460)",
      "at w.start (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:90:320276)",
      "at runMicrotasks (<anonymous>)",
      "at processTicksAndRejections (internal/process/task_queues.js:93:5)",
      "at async t.CellExecutionQueue.executeQueuedCells (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:90:334803)",
      "at async t.CellExecutionQueue.start (c:\\Users\\same\\.vscode\\extensions\\ms-toolsai.jupyter-2021.8.1195043623\\out\\client\\extension.js:90:334343)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "source": [
    "calculate_wer(cnn_rnn,\"CNN RNN\",audio_gen, 'validation',1000)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "processed 100 in 0 minutes\n",
      "processed 200 in 0 minutes\n",
      "processed 300 in 1 minutes\n",
      "processed 400 in 1 minutes\n",
      "processed 500 in 1 minutes\n",
      "processed 600 in 2 minutes\n",
      "processed 700 in 2 minutes\n",
      "processed 800 in 3 minutes\n",
      "processed 900 in 3 minutes\n",
      "Total time: 3.843780 minutes\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[65,\n",
       " 44,\n",
       " 85,\n",
       " 61,\n",
       " 70,\n",
       " 50,\n",
       " 42,\n",
       " 71,\n",
       " 64,\n",
       " 44,\n",
       " 35,\n",
       " 26,\n",
       " 44,\n",
       " 43,\n",
       " 34,\n",
       " 37,\n",
       " 28,\n",
       " 82,\n",
       " 51,\n",
       " 38,\n",
       " 37,\n",
       " 74,\n",
       " 42,\n",
       " 33,\n",
       " 49,\n",
       " 57,\n",
       " 40,\n",
       " 71,\n",
       " 58,\n",
       " 58,\n",
       " 76,\n",
       " 52,\n",
       " 42,\n",
       " 54,\n",
       " 74,\n",
       " 60,\n",
       " 61,\n",
       " 54,\n",
       " 53,\n",
       " 45,\n",
       " 49,\n",
       " 70,\n",
       " 46,\n",
       " 42,\n",
       " 50,\n",
       " 45,\n",
       " 40,\n",
       " 66,\n",
       " 51,\n",
       " 47,\n",
       " 26,\n",
       " 80,\n",
       " 68,\n",
       " 39,\n",
       " 68,\n",
       " 46,\n",
       " 56,\n",
       " 45,\n",
       " 43,\n",
       " 61,\n",
       " 42,\n",
       " 41,\n",
       " 46,\n",
       " 45,\n",
       " 65,\n",
       " 77,\n",
       " 44,\n",
       " 92,\n",
       " 101,\n",
       " 35,\n",
       " 44,\n",
       " 39,\n",
       " 36,\n",
       " 82,\n",
       " 51,\n",
       " 50,\n",
       " 64,\n",
       " 58,\n",
       " 53,\n",
       " 49,\n",
       " 86,\n",
       " 43,\n",
       " 73,\n",
       " 59,\n",
       " 59,\n",
       " 26,\n",
       " 63,\n",
       " 67,\n",
       " 31,\n",
       " 25,\n",
       " 37,\n",
       " 49,\n",
       " 50,\n",
       " 36,\n",
       " 51,\n",
       " 41,\n",
       " 52,\n",
       " 32,\n",
       " 48,\n",
       " 46,\n",
       " 32,\n",
       " 87,\n",
       " 60,\n",
       " 25,\n",
       " 66,\n",
       " 41,\n",
       " 40,\n",
       " 47,\n",
       " 60,\n",
       " 48,\n",
       " 79,\n",
       " 46,\n",
       " 104,\n",
       " 44,\n",
       " 38,\n",
       " 69,\n",
       " 72,\n",
       " 90,\n",
       " 71,\n",
       " 45,\n",
       " 37,\n",
       " 31,\n",
       " 57,\n",
       " 42,\n",
       " 46,\n",
       " 27,\n",
       " 42,\n",
       " 38,\n",
       " 54,\n",
       " 40,\n",
       " 43,\n",
       " 38,\n",
       " 28,\n",
       " 42,\n",
       " 40,\n",
       " 52,\n",
       " 50,\n",
       " 78,\n",
       " 60,\n",
       " 42,\n",
       " 39,\n",
       " 42,\n",
       " 28,\n",
       " 25,\n",
       " 25,\n",
       " 41,\n",
       " 29,\n",
       " 30,\n",
       " 58,\n",
       " 37,\n",
       " 23,\n",
       " 41,\n",
       " 78,\n",
       " 45,\n",
       " 113,\n",
       " 58,\n",
       " 60,\n",
       " 37,\n",
       " 33,\n",
       " 31,\n",
       " 71,\n",
       " 37,\n",
       " 32,\n",
       " 32,\n",
       " 65,\n",
       " 56,\n",
       " 51,\n",
       " 83,\n",
       " 24,\n",
       " 35,\n",
       " 47,\n",
       " 65,\n",
       " 26,\n",
       " 25,\n",
       " 48,\n",
       " 36,\n",
       " 38,\n",
       " 57,\n",
       " 46,\n",
       " 55,\n",
       " 35,\n",
       " 41,\n",
       " 42,\n",
       " 65,\n",
       " 62,\n",
       " 49,\n",
       " 37,\n",
       " 49,\n",
       " 39,\n",
       " 27,\n",
       " 51,\n",
       " 71,\n",
       " 42,\n",
       " 51,\n",
       " 37,\n",
       " 68,\n",
       " 48,\n",
       " 43,\n",
       " 39,\n",
       " 57,\n",
       " 32,\n",
       " 67,\n",
       " 49,\n",
       " 46,\n",
       " 71,\n",
       " 34,\n",
       " 35,\n",
       " 44,\n",
       " 72,\n",
       " 41,\n",
       " 28,\n",
       " 36,\n",
       " 50,\n",
       " 27,\n",
       " 35,\n",
       " 72,\n",
       " 32,\n",
       " 30,\n",
       " 24,\n",
       " 47,\n",
       " 39,\n",
       " 47,\n",
       " 59,\n",
       " 42,\n",
       " 47,\n",
       " 37,\n",
       " 43,\n",
       " 36,\n",
       " 55,\n",
       " 48,\n",
       " 41,\n",
       " 53,\n",
       " 51,\n",
       " 54,\n",
       " 44,\n",
       " 48,\n",
       " 92,\n",
       " 31,\n",
       " 38,\n",
       " 50,\n",
       " 39,\n",
       " 49,\n",
       " 66,\n",
       " 57,\n",
       " 39,\n",
       " 42,\n",
       " 34,\n",
       " 55,\n",
       " 60,\n",
       " 25,\n",
       " 56,\n",
       " 50,\n",
       " 59,\n",
       " 33,\n",
       " 38,\n",
       " 29,\n",
       " 69,\n",
       " 64,\n",
       " 50,\n",
       " 45,\n",
       " 42,\n",
       " 61,\n",
       " 62,\n",
       " 42,\n",
       " 39,\n",
       " 37,\n",
       " 32,\n",
       " 87,\n",
       " 63,\n",
       " 34,\n",
       " 71,\n",
       " 24,\n",
       " 55,\n",
       " 27,\n",
       " 43,\n",
       " 108,\n",
       " 70,\n",
       " 85,\n",
       " 52,\n",
       " 56,\n",
       " 48,\n",
       " 29,\n",
       " 62,\n",
       " 42,\n",
       " 86,\n",
       " 62,\n",
       " 51,\n",
       " 49,\n",
       " 36,\n",
       " 73,\n",
       " 55,\n",
       " 59,\n",
       " 40,\n",
       " 56,\n",
       " 59,\n",
       " 88,\n",
       " 68,\n",
       " 23,\n",
       " 84,\n",
       " 74,\n",
       " 84,\n",
       " 42,\n",
       " 27,\n",
       " 63,\n",
       " 71,\n",
       " 27,\n",
       " 37,\n",
       " 27,\n",
       " 75,\n",
       " 70,\n",
       " 53,\n",
       " 41,\n",
       " 54,\n",
       " 77,\n",
       " 43,\n",
       " 48,\n",
       " 55,\n",
       " 51,\n",
       " 37,\n",
       " 38,\n",
       " 40,\n",
       " 28,\n",
       " 53,\n",
       " 37,\n",
       " 36,\n",
       " 59,\n",
       " 39,\n",
       " 37,\n",
       " 59,\n",
       " 39,\n",
       " 39,\n",
       " 58,\n",
       " 35,\n",
       " 32,\n",
       " 37,\n",
       " 55,\n",
       " 51,\n",
       " 53,\n",
       " 60,\n",
       " 51,\n",
       " 59,\n",
       " 52,\n",
       " 30,\n",
       " 58,\n",
       " 43,\n",
       " 55,\n",
       " 34,\n",
       " 52,\n",
       " 39,\n",
       " 51,\n",
       " 34,\n",
       " 31,\n",
       " 39,\n",
       " 59,\n",
       " 39,\n",
       " 34,\n",
       " 34,\n",
       " 51,\n",
       " 42,\n",
       " 47,\n",
       " 29,\n",
       " 42,\n",
       " 35,\n",
       " 47,\n",
       " 48,\n",
       " 62,\n",
       " 27,\n",
       " 39,\n",
       " 42,\n",
       " 73,\n",
       " 41,\n",
       " 44,\n",
       " 31,\n",
       " 59,\n",
       " 52,\n",
       " 97,\n",
       " 52,\n",
       " 55,\n",
       " 55,\n",
       " 77,\n",
       " 42,\n",
       " 37,\n",
       " 60,\n",
       " 48,\n",
       " 56,\n",
       " 47,\n",
       " 65,\n",
       " 55,\n",
       " 53,\n",
       " 29,\n",
       " 46,\n",
       " 38,\n",
       " 58,\n",
       " 55,\n",
       " 41,\n",
       " 36,\n",
       " 34,\n",
       " 34,\n",
       " 34,\n",
       " 66,\n",
       " 35,\n",
       " 37,\n",
       " 52,\n",
       " 24,\n",
       " 40,\n",
       " 37,\n",
       " 43,\n",
       " 54,\n",
       " 77,\n",
       " 29,\n",
       " 54,\n",
       " 69,\n",
       " 44,\n",
       " 45,\n",
       " 37,\n",
       " 68,\n",
       " 54,\n",
       " 70,\n",
       " 51,\n",
       " 44,\n",
       " 52,\n",
       " 67,\n",
       " 50,\n",
       " 48,\n",
       " 65,\n",
       " 56,\n",
       " 58,\n",
       " 53,\n",
       " 38,\n",
       " 59,\n",
       " 69,\n",
       " 31,\n",
       " 40,\n",
       " 86,\n",
       " 47,\n",
       " 85,\n",
       " 68,\n",
       " 35,\n",
       " 69,\n",
       " 73,\n",
       " 30,\n",
       " 40,\n",
       " 52,\n",
       " 42,\n",
       " 26,\n",
       " 44,\n",
       " 71,\n",
       " 68,\n",
       " 51,\n",
       " 58,\n",
       " 45,\n",
       " 82,\n",
       " 78,\n",
       " 45,\n",
       " 59,\n",
       " 47,\n",
       " 63,\n",
       " 82,\n",
       " 45,\n",
       " 71,\n",
       " 36,\n",
       " 70,\n",
       " 51,\n",
       " 46,\n",
       " 84,\n",
       " 31,\n",
       " 33,\n",
       " 63,\n",
       " 54,\n",
       " 42,\n",
       " 50,\n",
       " 40,\n",
       " 70,\n",
       " 38,\n",
       " 55,\n",
       " 70,\n",
       " 66,\n",
       " 47,\n",
       " 37,\n",
       " 68,\n",
       " 33,\n",
       " 66,\n",
       " 52,\n",
       " 60,\n",
       " 78,\n",
       " 36,\n",
       " 76,\n",
       " 96,\n",
       " 31,\n",
       " 48,\n",
       " 63,\n",
       " 89,\n",
       " 63,\n",
       " 51,\n",
       " 29,\n",
       " 38,\n",
       " 38,\n",
       " 33,\n",
       " 62,\n",
       " 34,\n",
       " 46,\n",
       " 47,\n",
       " 39,\n",
       " 31,\n",
       " 40,\n",
       " 41,\n",
       " 83,\n",
       " 95,\n",
       " 92,\n",
       " 81,\n",
       " 44,\n",
       " 66,\n",
       " 55,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 63,\n",
       " 33,\n",
       " 78,\n",
       " 48,\n",
       " 73,\n",
       " 76,\n",
       " 41,\n",
       " 58,\n",
       " 75,\n",
       " 34,\n",
       " 47,\n",
       " 76,\n",
       " 70,\n",
       " 20,\n",
       " 62,\n",
       " 49,\n",
       " 32,\n",
       " 26,\n",
       " 31,\n",
       " 41,\n",
       " 39,\n",
       " 43,\n",
       " 75,\n",
       " 68,\n",
       " 39,\n",
       " 48,\n",
       " 48,\n",
       " 75,\n",
       " 33,\n",
       " 54,\n",
       " 56,\n",
       " 41,\n",
       " 87,\n",
       " 76,\n",
       " 46,\n",
       " 60,\n",
       " 61,\n",
       " 20,\n",
       " 54,\n",
       " 45,\n",
       " 24,\n",
       " 48,\n",
       " 27,\n",
       " 40,\n",
       " 32,\n",
       " 38,\n",
       " 54,\n",
       " 96,\n",
       " 45,\n",
       " 41,\n",
       " 40,\n",
       " 41,\n",
       " 49,\n",
       " 91,\n",
       " 56,\n",
       " 40,\n",
       " 44,\n",
       " 33,\n",
       " 43,\n",
       " 45,\n",
       " 63,\n",
       " 70,\n",
       " 58,\n",
       " 39,\n",
       " 48,\n",
       " 46,\n",
       " 57,\n",
       " 78,\n",
       " 79,\n",
       " 45,\n",
       " 68,\n",
       " 54,\n",
       " 92,\n",
       " 42,\n",
       " 67,\n",
       " 77,\n",
       " 39,\n",
       " 65,\n",
       " 54,\n",
       " 48,\n",
       " 48,\n",
       " 61,\n",
       " 37,\n",
       " 35,\n",
       " 105,\n",
       " 31,\n",
       " 43,\n",
       " 33,\n",
       " 32,\n",
       " 30,\n",
       " 51,\n",
       " 52,\n",
       " 45,\n",
       " 34,\n",
       " 80,\n",
       " 57,\n",
       " 47,\n",
       " 86,\n",
       " 71,\n",
       " 37,\n",
       " 44,\n",
       " 47,\n",
       " 43,\n",
       " 36,\n",
       " 67,\n",
       " 45,\n",
       " 53,\n",
       " 34,\n",
       " 48,\n",
       " 74,\n",
       " 33,\n",
       " 63,\n",
       " 81,\n",
       " 85,\n",
       " 42,\n",
       " 36,\n",
       " 46,\n",
       " 55,\n",
       " 82,\n",
       " 41,\n",
       " 73,\n",
       " 35,\n",
       " 49,\n",
       " 32,\n",
       " 45,\n",
       " 32,\n",
       " 44,\n",
       " 48,\n",
       " 25,\n",
       " 32,\n",
       " 86,\n",
       " 60,\n",
       " 75,\n",
       " 69,\n",
       " 39,\n",
       " 52,\n",
       " 60,\n",
       " 60,\n",
       " 47,\n",
       " 65,\n",
       " 37,\n",
       " 31,\n",
       " 50,\n",
       " 39,\n",
       " 54,\n",
       " 49,\n",
       " 40,\n",
       " 42,\n",
       " 44,\n",
       " 35,\n",
       " 32,\n",
       " 40,\n",
       " 70,\n",
       " 58,\n",
       " 60,\n",
       " 51,\n",
       " 36,\n",
       " 66,\n",
       " 30,\n",
       " 29,\n",
       " 49,\n",
       " 47,\n",
       " 53,\n",
       " 26,\n",
       " 37,\n",
       " 58,\n",
       " 56,\n",
       " 74,\n",
       " 45,\n",
       " 77,\n",
       " 45,\n",
       " 30,\n",
       " 37,\n",
       " 44,\n",
       " 32,\n",
       " 51,\n",
       " 52,\n",
       " 28,\n",
       " 36,\n",
       " 45,\n",
       " 78,\n",
       " 48,\n",
       " 51,\n",
       " 42,\n",
       " 52,\n",
       " 32,\n",
       " 31,\n",
       " 44,\n",
       " 34,\n",
       " 81,\n",
       " 51,\n",
       " 48,\n",
       " 34,\n",
       " 47,\n",
       " 37,\n",
       " 39,\n",
       " 40,\n",
       " 37,\n",
       " 84,\n",
       " 53,\n",
       " 50,\n",
       " 77,\n",
       " 38,\n",
       " 31,\n",
       " 51,\n",
       " 31,\n",
       " 47,\n",
       " 37,\n",
       " 43,\n",
       " 37,\n",
       " 49,\n",
       " 42,\n",
       " 42,\n",
       " 37,\n",
       " 40,\n",
       " 49,\n",
       " 34,\n",
       " 45,\n",
       " 49,\n",
       " 53,\n",
       " 25,\n",
       " 55,\n",
       " 48,\n",
       " 38,\n",
       " 83,\n",
       " 50,\n",
       " 51,\n",
       " 35,\n",
       " 41,\n",
       " 34,\n",
       " 42,\n",
       " 27,\n",
       " 36,\n",
       " 35,\n",
       " 44,\n",
       " 44,\n",
       " 33,\n",
       " 36,\n",
       " 38,\n",
       " 41,\n",
       " 46,\n",
       " 46,\n",
       " 47,\n",
       " 77,\n",
       " 63,\n",
       " 46,\n",
       " 28,\n",
       " 88,\n",
       " 35,\n",
       " 32,\n",
       " 50,\n",
       " 58,\n",
       " 93,\n",
       " 57,\n",
       " 75,\n",
       " 53,\n",
       " 90,\n",
       " 73,\n",
       " 23,\n",
       " 27,\n",
       " 31,\n",
       " 69,\n",
       " 32,\n",
       " 44,\n",
       " 73,\n",
       " 51,\n",
       " 57,\n",
       " 49,\n",
       " 40,\n",
       " 72,\n",
       " 39,\n",
       " 33,\n",
       " 54,\n",
       " 45,\n",
       " 66,\n",
       " 86,\n",
       " 47,\n",
       " 32,\n",
       " 48,\n",
       " 34,\n",
       " 37,\n",
       " 34,\n",
       " 36,\n",
       " 64,\n",
       " 29,\n",
       " 50,\n",
       " 40,\n",
       " 72,\n",
       " 58,\n",
       " 33,\n",
       " 40,\n",
       " 55,\n",
       " 40,\n",
       " 41,\n",
       " 41,\n",
       " 32,\n",
       " 40,\n",
       " 60,\n",
       " 31,\n",
       " 44,\n",
       " 56,\n",
       " 49,\n",
       " 38,\n",
       " 29,\n",
       " 38,\n",
       " 45,\n",
       " 37,\n",
       " 28,\n",
       " 53,\n",
       " 35,\n",
       " 38,\n",
       " 38,\n",
       " 48,\n",
       " 31,\n",
       " 47,\n",
       " 66,\n",
       " 35,\n",
       " 35,\n",
       " 28,\n",
       " 71,\n",
       " 46,\n",
       " 52,\n",
       " 30,\n",
       " 45,\n",
       " 34,\n",
       " 57,\n",
       " 49,\n",
       " 38,\n",
       " 43,\n",
       " 61,\n",
       " 46,\n",
       " 46,\n",
       " 48,\n",
       " 74,\n",
       " 29,\n",
       " 64,\n",
       " 81,\n",
       " 84,\n",
       " 43,\n",
       " 35,\n",
       " 48,\n",
       " 57,\n",
       " 84,\n",
       " 41,\n",
       " 72,\n",
       " 35,\n",
       " 48,\n",
       " 32,\n",
       " 45,\n",
       " 30,\n",
       " 44,\n",
       " 47,\n",
       " 57,\n",
       " 87,\n",
       " 57,\n",
       " 77,\n",
       " 68,\n",
       " 38,\n",
       " 49,\n",
       " 56,\n",
       " 59,\n",
       " 48,\n",
       " 67,\n",
       " 35,\n",
       " 30,\n",
       " 49,\n",
       " 39,\n",
       " 78,\n",
       " 63,\n",
       " 42,\n",
       " 39,\n",
       " 37,\n",
       " 36,\n",
       " 83,\n",
       " 52,\n",
       " 38,\n",
       " 48,\n",
       " 78,\n",
       " 45,\n",
       " 38,\n",
       " 52,\n",
       " 59,\n",
       " 69,\n",
       " 53,\n",
       " 65,\n",
       " 33,\n",
       " 57,\n",
       " 48,\n",
       " 48,\n",
       " 74,\n",
       " 70,\n",
       " 35,\n",
       " 50,\n",
       " 68,\n",
       " 57,\n",
       " 66,\n",
       " 44,\n",
       " 64,\n",
       " 56,\n",
       " 34,\n",
       " 38,\n",
       " 80,\n",
       " 37,\n",
       " 36,\n",
       " 33,\n",
       " 50,\n",
       " 60,\n",
       " 49,\n",
       " 27,\n",
       " 33,\n",
       " 45,\n",
       " 45,\n",
       " 49,\n",
       " 41,\n",
       " 62,\n",
       " 43,\n",
       " 43,\n",
       " 37,\n",
       " 38,\n",
       " 46,\n",
       " 46,\n",
       " 35,\n",
       " 54,\n",
       " 42,\n",
       " 34,\n",
       " 52,\n",
       " 55,\n",
       " 32,\n",
       " 59,\n",
       " 49,\n",
       " 75,\n",
       " 61,\n",
       " 37,\n",
       " 80,\n",
       " 59,\n",
       " 72,\n",
       " 33,\n",
       " 33,\n",
       " 51,\n",
       " 78,\n",
       " 92,\n",
       " 58,\n",
       " 39,\n",
       " 40,\n",
       " 70,\n",
       " 67,\n",
       " 64,\n",
       " 42,\n",
       " 62,\n",
       " 57,\n",
       " 52,\n",
       " 38,\n",
       " 45,\n",
       " 33,\n",
       " 48,\n",
       " 35,\n",
       " 44,\n",
       " 29,\n",
       " 41,\n",
       " 31,\n",
       " 27,\n",
       " 32,\n",
       " 52,\n",
       " 74,\n",
       " 86,\n",
       " 70,\n",
       " 92,\n",
       " 80,\n",
       " 65,\n",
       " 52,\n",
       " 34,\n",
       " 71,\n",
       " 71,\n",
       " 58,\n",
       " 45,\n",
       " 45,\n",
       " 60,\n",
       " 72,\n",
       " 53,\n",
       " 40,\n",
       " 43,\n",
       " 79,\n",
       " 33]"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}