{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\r\n",
    "import traceback\r\n",
    "import os,sys\r\n",
    "\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from MetaCreate import MetaCreate\r\n",
    "from AudioManipulator import AudioManipulator\r\n",
    "from preprocess_uitls import pad_audio_files, featurize\r\n",
    "from utils import char_map,index_map, int_sequence_to_text ,text_to_int_sequence\r\n",
    "from ctc_utils import ctc_lambda_func, add_ctc_loss, cnn_output_length\r\n",
    "\r\n",
    "\r\n",
    "import librosa\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\r\n",
    "\r\n",
    "from tensorflow.keras import backend as K\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.layers  import (BatchNormalization, Conv1D, Dense, Input, \r\n",
    "    TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\r\n",
    "    \r\n",
    "# from keras.utils.vis_utils import plot_model\r\n",
    "\r\n",
    "\r\n",
    "import _pickle as pickle\r\n",
    "from numpy.lib.stride_tricks import as_strided\r\n",
    "\r\n",
    "from keras.layers import (Input, Lambda)\r\n",
    "from tensorflow.keras.optimizers import SGD\r\n",
    "from keras.callbacks import ModelCheckpoint   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "def simple_rnn(input_dim, units, activation, output_dim=29):\r\n",
    "    \"\"\" Build a recurrent network for speech \r\n",
    "    \"\"\"\r\n",
    "    # Main acoustic input\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    # Add recurrent layer\r\n",
    "    simp_rnn = GRU(units, activation=activation,\r\n",
    "        return_sequences=True, implementation=2, name='rnn')(input_data)\r\n",
    "    bn_rnn = BatchNormalization()(simp_rnn)\r\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\r\n",
    "    # Add softmax activation layer\r\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\r\n",
    "    # Specify the model\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\r\n",
    "    model.output_length = lambda x: x\r\n",
    "    print(model.summary())\r\n",
    "    # plot_model(model, to_file='models/model_1.png')\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def model_2(input_dim, filters, kernel_size, conv_stride,\r\n",
    "    conv_border_mode, units, output_dim=29, dropout_rate=0.5, number_of_layers=2, \r\n",
    "    cell=GRU, activation='tanh'):\r\n",
    "    \"\"\" Build a deep network for speech \r\n",
    "    \"\"\"\r\n",
    "    # Main acoustic input\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    # TODO: Specify the layers in your network\r\n",
    "    conv_1d = Conv1D(filters, kernel_size, \r\n",
    "                     strides=conv_stride, \r\n",
    "                     padding=conv_border_mode,\r\n",
    "                     activation='relu',\r\n",
    "                     name='layer_1_conv',\r\n",
    "                     dilation_rate=1)(input_data)\r\n",
    "    conv_bn = BatchNormalization(name='conv_batch_norm')(conv_1d)\r\n",
    "\r\n",
    "\r\n",
    "    if number_of_layers == 1:\r\n",
    "        layer = cell(units, activation=activation,\r\n",
    "            return_sequences=True, implementation=2, name='rnn_1', dropout=dropout_rate)(conv_bn)\r\n",
    "        layer = BatchNormalization(name='bt_rnn_1')(layer)\r\n",
    "    else:\r\n",
    "        layer = cell(units, activation=activation,\r\n",
    "                    return_sequences=True, implementation=2, name='rnn_1', dropout=dropout_rate)(conv_bn)\r\n",
    "        layer = BatchNormalization(name='bt_rnn_1')(layer)\r\n",
    "\r\n",
    "        for i in range(number_of_layers - 2):\r\n",
    "            layer = cell(units, activation=activation,\r\n",
    "                        return_sequences=True, implementation=2, name='rnn_{}'.format(i+2), dropout=dropout_rate)(layer)\r\n",
    "            layer = BatchNormalization(name='bt_rnn_{}'.format(i+2))(layer)\r\n",
    "\r\n",
    "        layer = cell(units, activation=activation,\r\n",
    "                    return_sequences=True, implementation=2, name='final_layer_of_rnn')(layer)\r\n",
    "        layer = BatchNormalization(name='bt_rnn_final')(layer)\r\n",
    "    \r\n",
    "\r\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(layer)\r\n",
    "    # TODO: Add softmax activation layer\r\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\r\n",
    "    # Specify the model\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\r\n",
    "    # TODO: Specify model.output_length\r\n",
    "    model.output_length = lambda x: cnn_output_length(\r\n",
    "        x, kernel_size, conv_border_mode, conv_stride)\r\n",
    "    print(model.summary())\r\n",
    "    # plot_model(model, to_file='models/model_2.png', show_shapes=True)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def cnn_rnn_model(input_dim, filters, kernel_size, conv_stride,\r\n",
    "    conv_border_mode, units, output_dim=29):\r\n",
    "    \"\"\" Build a recurrent + convolutional network for speech \r\n",
    "    \"\"\"\r\n",
    "    # Main acoustic input\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    # Add convolutional layer\r\n",
    "    conv_1d = Conv1D(filters, kernel_size, \r\n",
    "                     strides=conv_stride, \r\n",
    "                     padding=conv_border_mode,\r\n",
    "                     activation='relu',\r\n",
    "                     name='conv1d')(input_data)\r\n",
    "    # Add batch normalization\r\n",
    "    bn_cnn = BatchNormalization(name='bn_conv_1d')(conv_1d)\r\n",
    "    # Add a recurrent layer\r\n",
    "    simp_rnn = SimpleRNN(units, activation='relu',\r\n",
    "        return_sequences=True,  name='rnn')(bn_cnn)\r\n",
    "    # TODO: Add batch normalization\r\n",
    "    \r\n",
    "   \r\n",
    "    bn_rnn = BatchNormalization()(simp_rnn)\r\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\r\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\r\n",
    "    # Add softmax activation layer\r\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\r\n",
    "    # Specify the model\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\r\n",
    "    model.output_length = lambda x: cnn_output_length(\r\n",
    "        x, kernel_size, conv_border_mode, conv_stride)\r\n",
    "    # model.output_length = lambda x: x\r\n",
    "    print(model.summary())\r\n",
    "    \r\n",
    "    return model\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "def bidirectional_rnn_model_gpu(input_dim, units, output_dim=29):\r\n",
    "    \"\"\" Build a bidirectional recurrent network for speech\r\n",
    "    \"\"\"\r\n",
    "    # Main acoustic input\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    # TODO: Add bidirectional recurrent layer\r\n",
    "    bidir_rnn = Bidirectional(GRU(units,\r\n",
    "                                  return_sequences=True,\r\n",
    "                                  implementation=2,\r\n",
    "                                  name='bi_rnn',\r\n",
    "                                  activation = 'tanh',\r\n",
    "                                recurrent_activation = 'sigmoid',\r\n",
    "                                recurrent_dropout = 0,\r\n",
    "                                unroll = False,\r\n",
    "                                use_bias = True,\r\n",
    "                                 ))(input_data)\r\n",
    "\r\n",
    "                                 \r\n",
    "    bn_bidir_rnn = BatchNormalization( name='norm_bidir_rnn')(bidir_rnn)\r\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\r\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_bidir_rnn)\r\n",
    "    # Add softmax activation layer\r\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\r\n",
    "    # Specify the model\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\r\n",
    "    model.output_length = lambda x: x\r\n",
    "    print(model.summary())\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "def bidirectional_rnn_model(input_dim, units, output_dim=29):\r\n",
    "    \"\"\" Build a bidirectional recurrent network for speech\r\n",
    "    \"\"\"\r\n",
    "    # Main acoustic input\r\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\r\n",
    "    # TODO: Add bidirectional recurrent layer\r\n",
    "    bidir_rnn = Bidirectional(GRU(units,\r\n",
    "                                  activation='softmax',\r\n",
    "                                  return_sequences=True,\r\n",
    "                                  implementation=2,\r\n",
    "                                  name='bi_rnn'\r\n",
    "                                 ))(input_data)\r\n",
    "    bn_bidir_rnn = BatchNormalization( name='norm_bidir_rnn')(bidir_rnn)\r\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\r\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_bidir_rnn)\r\n",
    "    # Add softmax activation layer\r\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\r\n",
    "    # Specify the model\r\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\r\n",
    "    model.output_length = lambda x: x\r\n",
    "    print(model.summary())\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import mlflow\r\n",
    "import mlflow.tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "data=pd.read_json('../artifacts/meta.json')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10179"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "data.drop(data[data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9357"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "with open('../artifacts/features.pkl','rb') as tel:\r\n",
    "    features=pickle.load(tel)\r\n",
    "    tel.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(len(features),len(data.text.to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9357 9357\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "valid_data=pd.read_json(\"../artifacts/valid_meta.json\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "valid_data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "valid_data.drop(valid_data[valid_data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "valid_data.text.count()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "with open('../artifacts/valid_features.pkl','rb') as val:\r\n",
    "    valid_features=pickle.load(val)\r\n",
    "    val.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "print(len(valid_features),len(valid_data.text.to_numpy()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1990 1990\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "from Batch import Batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "\r\n",
    "MODEL_NAME = \"bidirectional_rnn_gpu\"\r\n",
    "EPOCHS=10\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bidirectional RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "bidirectional_rnn_gpu=bidirectional_rnn_model_gpu(input_dim=26, \r\n",
    "                        units=250)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, None, 500)         417000    \n",
      "_________________________________________________________________\n",
      "norm_bidir_rnn (BatchNormali (None, None, 500)         2000      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, None, 29)          14529     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 433,529\n",
      "Trainable params: 432,529\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from Train import train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Bidirectional RNN GPU\")\r\n",
    "train(audio_gen, input_to_softmax=bidirectional_rnn_gpu, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/09 14:12:43 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'b627d8575e3440bb98bd1d94b37dda6d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 44s 1s/step - loss: 160.6900 - val_loss: 249.7360\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 36s 971ms/step - loss: 155.5684 - val_loss: 204.4467\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 30s 808ms/step - loss: 153.1183 - val_loss: 197.6223\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 32s 876ms/step - loss: 151.1606 - val_loss: 166.5286\n",
      "Epoch 5/10\n",
      "37/37 [==============================] - 34s 922ms/step - loss: 149.4014 - val_loss: 176.8793\n",
      "Epoch 6/10\n",
      "37/37 [==============================] - 31s 836ms/step - loss: 148.5265 - val_loss: 157.5194\n",
      "Epoch 7/10\n",
      "37/37 [==============================] - 32s 882ms/step - loss: 146.9373 - val_loss: 167.6052\n",
      "Epoch 8/10\n",
      "37/37 [==============================] - 45s 1s/step - loss: 146.3483 - val_loss: 156.4237\n",
      "Epoch 9/10\n",
      "37/37 [==============================] - 30s 812ms/step - loss: 147.9628 - val_loss: 157.6867\n",
      "Epoch 10/10\n",
      "37/37 [==============================] - 30s 821ms/step - loss: 146.6286 - val_loss: 169.6456\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/09 14:18:28 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "\r\n",
    "MODEL_NAME = \"simple_rnn\"\r\n",
    "EPOCHS=10\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "simple_rnn_model = simple_rnn(input_dim=26,\r\n",
    "                units=5,\r\n",
    "                activation='tanh',\r\n",
    "                output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, None, 5)           495       \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, None, 5)           20        \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, None, 29)          174       \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 689\n",
      "Trainable params: 679\n",
      "Non-trainable params: 10\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Simple RNN\")\r\n",
    "train(audio_gen, input_to_softmax=simple_rnn_model, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/09 14:35:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '822ca4f8a42f49e6a9915585f0ca1177', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "37/37 [==============================] - 28s 661ms/step - loss: 207.9806 - val_loss: 223.8220\n",
      "Epoch 2/10\n",
      "37/37 [==============================] - 25s 672ms/step - loss: 172.3360 - val_loss: 226.4976\n",
      "Epoch 3/10\n",
      "37/37 [==============================] - 34s 916ms/step - loss: 172.2853 - val_loss: 199.5817\n",
      "Epoch 4/10\n",
      "37/37 [==============================] - 25s 677ms/step - loss: 171.7939 - val_loss: 196.6637\n",
      "Epoch 5/10\n",
      "14/37 [==========>...................] - ETA: 11s - loss: 173.0780"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNN RNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "cnn_rnn_model = cnn_rnn_model(input_dim=26, # change to 13 if you would like to use MFCC features\r\n",
    "                        filters=250,\r\n",
    "                        kernel_size=4, \r\n",
    "                        conv_stride=1,\r\n",
    "                        conv_border_mode='same',\r\n",
    "                        units=200,output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 250)         26250     \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, None, 200)         90200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          5829      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 124,079\n",
      "Trainable params: 123,179\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}