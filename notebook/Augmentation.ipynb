{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import traceback\r\n",
    "import os,sys\r\n",
    "\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from MetaCreate import MetaCreate\r\n",
    "from AudioManipulator import AudioManipulator\r\n",
    "from preprocess_uitls import pad_audio_files, featurize\r\n",
    "from utils import char_map,index_map, int_sequence_to_text ,text_to_int_sequence\r\n",
    "\r\n",
    "\r\n",
    "import librosa\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\r\n",
    "\r\n",
    "    \r\n",
    "# from keras.utils.vis_utils import plot_model\r\n",
    "\r\n",
    "\r\n",
    "import _pickle as pickle\r\n",
    "from numpy.lib.stride_tricks import as_strided\r\n",
    "\r\n",
    "from Models import cnn_rnn_model,simple_rnn,model_2,bidirectional_rnn_model_gpu,bidirectional_rnn_model\r\n",
    "# from keras.callbacks import ModelCheckpoint   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "data=pd.read_json('../artifacts/meta.json')\r\n",
    "data.drop(data[data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/features.pkl','rb') as tel:\r\n",
    "    features=pickle.load(tel)\r\n",
    "    tel.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "valid_data=pd.read_json(\"../artifacts/valid_meta.json\")\r\n",
    "valid_data.drop(valid_data[valid_data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/valid_features.pkl','rb') as val:\r\n",
    "    valid_features=pickle.load(val)\r\n",
    "    val.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Augmentation\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from preprocess_uitls import pad_audio_files,featurize,pitch_audio,shift"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "import preprocess_uitls\r\n",
    "import importlib\r\n",
    "importlib.reload(preprocess_uitls)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'preprocess_uitls' from 'd:\\\\same\\\\Documents\\\\10Acadamy\\\\Week 4\\\\System\\\\Week-4\\\\scripts\\\\preprocess_uitls.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "data[\"audio\"]=pad_audio_files(data[\"path\"],98400)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "valid_data[\"audio\"]=pad_audio_files(valid_data[\"path\"],98400)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "pitched=pitch_audio(data[\"audio\"],-2,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "pitched_valid=pitch_audio(valid_data[\"audio\"],-1,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "pitched_features=featurize(pitched,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with open('../artifacts/pitched_features.pickle', 'wb') as p:\r\n",
    "        pickle.dump(pitched_features, p)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "pitched_valid_features=featurize(pitched_valid,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "pitched=\"\"\r\n",
    "pitched_valid=\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "with open('../artifacts/pitched_valid_features.pickle', 'wb') as v:\r\n",
    "        pickle.dump(pitched_valid_features, v)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "shifted=shift(data[\"audio\"],\"right\",1,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "shifted_valid=shift(valid_data[\"audio\"],\"right\",1,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "shifted_features=featurize(shifted,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "shifted_valid_features=featurize(shifted_valid,16000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "with open('../artifacts/shifted_features.pickle', 'wb') as v:\r\n",
    "        pickle.dump(shifted_features, v)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "with open('../artifacts/shifted_valid_features.pickle', 'wb') as vs:\r\n",
    "        pickle.dump(shifted_valid_features, vs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "shifted=\"\"\r\n",
    "shifted_valid=\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "with open('../artifacts/shifted_valid_features.pickle', 'rb') as vs:\r\n",
    "        shifted_valid_features=pickle.load( vs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open('../artifacts/shifted_features.pickle', 'rb') as v:\r\n",
    "        shifted_features=pickle.load( v)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "with open('../artifacts/pitched_features.pickle', 'rb') as t:\r\n",
    "        pitched_features=pickle.load( t)\r\n",
    "with open('../artifacts/pitched_valid_features.pickle', 'rb') as r:\r\n",
    "        pitched_valid_features=pickle.load( r)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "total_text=[]\r\n",
    "total_features=[]\r\n",
    "total_valid_text=[]\r\n",
    "total_valid_features=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "total_text=data[\"text\"].tolist()+data[\"text\"].tolist()+data[\"text\"].tolist()\r\n",
    "total_features=features+pitched_features+shifted_features\r\n",
    "total_valid_text=valid_data[\"text\"].tolist()+valid_data[\"text\"].tolist()+valid_data[\"text\"].tolist()\r\n",
    "total_valid_features=valid_features+pitched_valid_features+shifted_valid_features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "len(total_valid_features)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5970"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "data=[]\r\n",
    "valid_data=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "shifted_valid_features,shifted_features,pitched_features,pitched_valid_features=[],[],[],[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import mlflow\r\n",
    "import mlflow.tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from Batch import Batch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "cnn_rnn = cnn_rnn_model(input_dim=26, # change to 13 if you would like to use MFCC features\r\n",
    "                        filters=250,\r\n",
    "                        kernel_size=4, \r\n",
    "                        conv_stride=1,\r\n",
    "                        conv_border_mode='same',\r\n",
    "                        units=200,output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 250)         26250     \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, None, 200)         90200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 29)          5829      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 124,079\n",
      "Trainable params: 123,179\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "\r\n",
    "MODEL_NAME = \"cnn_rnn_augmented\"\r\n",
    "EPOCHS=50\r\n",
    "MINI_BATCH_SIZE = 200\r\n",
    "FEATURES_LIST=total_features\r\n",
    "\r\n",
    "TEXT_LIST=total_text\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=total_valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=total_valid_text\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from Train import train"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import mlflow\r\n",
    "import mlflow.tensorflow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"CNN RNN Augmented Data\")\r\n",
    "train(audio_gen, input_to_softmax=cnn_rnn, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/11 03:55:25 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '0c5173ae57bd4e87b1bb6c2c2348f095', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "140/140 [==============================] - 257s 1s/step - loss: 138.9264 - val_loss: nan\n",
      "Epoch 2/50\n",
      "140/140 [==============================] - 132s 945ms/step - loss: 108.4297 - val_loss: nan\n",
      "Epoch 3/50\n",
      "140/140 [==============================] - 134s 957ms/step - loss: 102.1505 - val_loss: nan\n",
      "Epoch 4/50\n",
      "140/140 [==============================] - 132s 947ms/step - loss: 98.6317 - val_loss: nan\n",
      "Epoch 5/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 96.4973 - val_loss: nan\n",
      "Epoch 6/50\n",
      "140/140 [==============================] - 132s 941ms/step - loss: 94.6732 - val_loss: nan\n",
      "Epoch 7/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 93.4806 - val_loss: nan\n",
      "Epoch 8/50\n",
      "140/140 [==============================] - 132s 946ms/step - loss: 92.2484 - val_loss: nan\n",
      "Epoch 9/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 91.3171 - val_loss: nan\n",
      "Epoch 10/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 90.3565 - val_loss: nan\n",
      "Epoch 11/50\n",
      "140/140 [==============================] - 133s 952ms/step - loss: 89.6490 - val_loss: nan\n",
      "Epoch 12/50\n",
      "140/140 [==============================] - 135s 968ms/step - loss: 88.8875 - val_loss: nan\n",
      "Epoch 13/50\n",
      "140/140 [==============================] - 132s 946ms/step - loss: 88.0059 - val_loss: nan\n",
      "Epoch 14/50\n",
      "140/140 [==============================] - 132s 945ms/step - loss: 87.4555 - val_loss: nan\n",
      "Epoch 15/50\n",
      "140/140 [==============================] - 133s 950ms/step - loss: 87.0682 - val_loss: nan\n",
      "Epoch 16/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 86.5923 - val_loss: nan\n",
      "Epoch 17/50\n",
      "140/140 [==============================] - 131s 940ms/step - loss: 86.0074 - val_loss: nan\n",
      "Epoch 18/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 85.6106 - val_loss: nan\n",
      "Epoch 19/50\n",
      "140/140 [==============================] - 132s 946ms/step - loss: 85.2211 - val_loss: nan\n",
      "Epoch 20/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 84.8430 - val_loss: nan\n",
      "Epoch 21/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 84.8485 - val_loss: nan\n",
      "Epoch 22/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 84.5170 - val_loss: nan\n",
      "Epoch 23/50\n",
      "140/140 [==============================] - 133s 952ms/step - loss: 84.3914 - val_loss: nan\n",
      "Epoch 24/50\n",
      "140/140 [==============================] - 132s 945ms/step - loss: 84.2934 - val_loss: nan\n",
      "Epoch 25/50\n",
      "140/140 [==============================] - 133s 949ms/step - loss: 84.6430 - val_loss: nan\n",
      "Epoch 26/50\n",
      "140/140 [==============================] - 133s 952ms/step - loss: 84.6515 - val_loss: nan\n",
      "Epoch 27/50\n",
      "140/140 [==============================] - 134s 957ms/step - loss: 84.6490 - val_loss: nan\n",
      "Epoch 28/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 85.4435 - val_loss: nan\n",
      "Epoch 29/50\n",
      "140/140 [==============================] - 132s 945ms/step - loss: 85.6094 - val_loss: nan\n",
      "Epoch 30/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 84.9630 - val_loss: nan\n",
      "Epoch 31/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 86.0839 - val_loss: nan\n",
      "Epoch 32/50\n",
      "140/140 [==============================] - 132s 947ms/step - loss: 92.6829 - val_loss: nan\n",
      "Epoch 33/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 86.8544 - val_loss: nan\n",
      "Epoch 34/50\n",
      "140/140 [==============================] - 132s 946ms/step - loss: 85.6488 - val_loss: nan\n",
      "Epoch 35/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 86.9178 - val_loss: nan\n",
      "Epoch 36/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 85.8904 - val_loss: nan\n",
      "Epoch 37/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 88.4972 - val_loss: nan\n",
      "Epoch 38/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 92.3104 - val_loss: nan\n",
      "Epoch 39/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 88.2155 - val_loss: nan\n",
      "Epoch 40/50\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 87.7594 - val_loss: nan\n",
      "Epoch 41/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 87.8008 - val_loss: nan\n",
      "Epoch 42/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 87.8449 - val_loss: nan\n",
      "Epoch 43/50\n",
      "140/140 [==============================] - 133s 951ms/step - loss: 90.2197 - val_loss: nan\n",
      "Epoch 44/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 89.8269 - val_loss: nan\n",
      "Epoch 45/50\n",
      "140/140 [==============================] - 132s 947ms/step - loss: 88.9766 - val_loss: nan\n",
      "Epoch 46/50\n",
      "140/140 [==============================] - 132s 944ms/step - loss: 88.8062 - val_loss: nan\n",
      "Epoch 47/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 88.5408 - val_loss: nan\n",
      "Epoch 48/50\n",
      "140/140 [==============================] - 133s 950ms/step - loss: 91.2981 - val_loss: nan\n",
      "Epoch 49/50\n",
      "140/140 [==============================] - 133s 947ms/step - loss: 93.4933 - val_loss: nan\n",
      "Epoch 50/50\n",
      "140/140 [==============================] - 133s 948ms/step - loss: 92.3683 - val_loss: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/11 05:48:26 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "\r\n",
    "MODEL_NAME = \"deep_augmented\"\r\n",
    "EPOCHS=20\r\n",
    "MINI_BATCH_SIZE = 200\r\n",
    "FEATURES_LIST=total_features\r\n",
    "\r\n",
    "TEXT_LIST=total_text\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=total_valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=total_valid_text\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from tensorflow.keras.layers import LSTM,Bidirectional,GRU"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "deep_speech = model_2(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='tanh',\r\n",
    "                dropout_rate=0.6,\r\n",
    "                cell=GRU,\r\n",
    "                number_of_layers=4,\r\n",
    "                output_dim=len(char_map)+1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 100)         10500     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "rnn_1 (GRU)                  (None, None, 250)         264000    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn_2 (GRU)                  (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_2 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn_3 (GRU)                  (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_3 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "final_layer_of_rnn (GRU)     (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_final (BatchNormaliza (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 29)          7279      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 1,415,679\n",
      "Trainable params: 1,413,479\n",
      "Non-trainable params: 2,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Deep Speech Augmented\")\r\n",
    "train(audio_gen, input_to_softmax=deep_speech, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/11 06:55:58 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'bc9d98ee181b45e4bf62e66adf4b1d4d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 136s 933ms/step - loss: 170.2697 - val_loss: 190.8794\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 129s 922ms/step - loss: 122.7602 - val_loss: 128.7204\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 130s 927ms/step - loss: 113.0096 - val_loss: 120.3921\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 129s 924ms/step - loss: 106.4057 - val_loss: 108.0783\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 130s 928ms/step - loss: 101.5190 - val_loss: 103.2491\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 130s 926ms/step - loss: 97.7856 - val_loss: 102.3560\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 130s 932ms/step - loss: 94.9363 - val_loss: 100.3597\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 132s 943ms/step - loss: 92.5748 - val_loss: 94.7952\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 133s 953ms/step - loss: 90.5144 - val_loss: 93.7049\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 131s 938ms/step - loss: 88.6871 - val_loss: 93.3765\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 133s 949ms/step - loss: 87.0895 - val_loss: 91.0878\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 139s 990ms/step - loss: 85.3526 - val_loss: 90.0028\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 122s 875ms/step - loss: 83.8833 - val_loss: 89.8900\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 132s 946ms/step - loss: 82.6780 - val_loss: 95.2424\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 129s 923ms/step - loss: 81.3792 - val_loss: 93.2083\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 128s 916ms/step - loss: 80.2470 - val_loss: 91.3981\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 134s 956ms/step - loss: 79.2693 - val_loss: 90.3898\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 130s 928ms/step - loss: 78.2149 - val_loss: 89.1341\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 126s 900ms/step - loss: 77.1315 - val_loss: 92.8923\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 125s 893ms/step - loss: 76.3251 - val_loss: 88.9754\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/11 07:39:27 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "import Models\r\n",
    "import importlib\r\n",
    "importlib.reload(Models)\r\n",
    "from Models import model_3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "\r\n",
    "MODEL_NAME = \"deep_bidirectional_augmented\"\r\n",
    "EPOCHS=20\r\n",
    "MINI_BATCH_SIZE = 200\r\n",
    "FEATURES_LIST=total_features\r\n",
    "\r\n",
    "TEXT_LIST=total_text\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=total_valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=total_valid_text\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "deep_speech2 = model_3(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='tanh',\r\n",
    "                dropout_rate=0.6,\r\n",
    "                number_of_layers=1,\r\n",
    "                output_dim=len(char_map)+1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 100)         10500     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, None, 500)         528000    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 500)         2000      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 29)          14529     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 555,429\n",
      "Trainable params: 554,229\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Deep Speech Augmented\")\r\n",
    "train(audio_gen, input_to_softmax=deep_speech2, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/11 08:15:16 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'e647f96f593a42afb18c522e5d1d72a3', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 117s 756ms/step - loss: 168.8782 - val_loss: 158.7168\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 104s 743ms/step - loss: 130.6323 - val_loss: 125.5214\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 106s 761ms/step - loss: 120.8133 - val_loss: 116.1417\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 103s 734ms/step - loss: 108.7661 - val_loss: 113.8748\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 104s 741ms/step - loss: 103.9581 - val_loss: 108.4986\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 104s 745ms/step - loss: 100.4474 - val_loss: 101.1788\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 105s 748ms/step - loss: 97.9822 - val_loss: 101.6945\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 102s 730ms/step - loss: 95.8176 - val_loss: 103.2539\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 108s 774ms/step - loss: 94.2637 - val_loss: 94.2850\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 111s 791ms/step - loss: 92.7976 - val_loss: 103.6712\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 109s 783ms/step - loss: 91.6411 - val_loss: 96.8242\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 114s 813ms/step - loss: 90.5093 - val_loss: 92.2371\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 101s 723ms/step - loss: 89.5101 - val_loss: 95.6668\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 107s 768ms/step - loss: 88.6142 - val_loss: 95.2052\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 103s 737ms/step - loss: 87.9570 - val_loss: 91.1283\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 102s 729ms/step - loss: 87.1576 - val_loss: 90.4615\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 104s 745ms/step - loss: 86.3034 - val_loss: 89.4936\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 105s 750ms/step - loss: 85.6957 - val_loss: 89.8498\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 102s 732ms/step - loss: 85.1531 - val_loss: 88.4782\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 105s 753ms/step - loss: 84.5860 - val_loss: 92.5901\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/11 08:50:36 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"D:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py:805: UserWarning: Logging to MLflow failed: module 'keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Deep Speech Augmented\")\r\n",
    "train(audio_gen, input_to_softmax=deep_speech2, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/08/11 08:50:41 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '98ddf6d3e0464ac2a311f868a9746aec', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 112s 776ms/step - loss: 83.9986 - val_loss: 89.0362\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 102s 729ms/step - loss: 83.4881 - val_loss: 91.5093\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 100s 713ms/step - loss: 83.1177 - val_loss: 93.2569\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 131s 941ms/step - loss: 82.6347 - val_loss: 92.3615\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 176s 1s/step - loss: 82.0475 - val_loss: 90.0516\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 107s 765ms/step - loss: 81.7676 - val_loss: 89.1217\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 98s 704ms/step - loss: 81.3305 - val_loss: 90.2516\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 97s 691ms/step - loss: 81.1707 - val_loss: 87.3265\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 97s 693ms/step - loss: 80.8007 - val_loss: 90.2307\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 97s 694ms/step - loss: 80.5324 - val_loss: 88.8673\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 97s 694ms/step - loss: 80.1677 - val_loss: 87.5680\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 101s 719ms/step - loss: 79.7754 - val_loss: 89.9901\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 100s 717ms/step - loss: 79.5166 - val_loss: 89.1163\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 99s 711ms/step - loss: 79.2719 - val_loss: 91.0005\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 101s 725ms/step - loss: 79.0203 - val_loss: 94.5388\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 105s 753ms/step - loss: 78.6881 - val_loss: 90.3788\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 114s 814ms/step - loss: 78.6492 - val_loss: 90.6224\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 106s 759ms/step - loss: 78.4997 - val_loss: 89.6601\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 100s 718ms/step - loss: 78.0642 - val_loss: 91.6858\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 107s 762ms/step - loss: 77.8996 - val_loss: 88.3888\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "deep_speech_4 = model_2(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='sigmoid',\r\n",
    "                dropout_rate=0.7,\r\n",
    "                number_of_layers=4,\r\n",
    "                output_dim=len(char_map)+1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "\r\n",
    "MODEL_NAME = \"deep_speech\"\r\n",
    "EPOCHS=40\r\n",
    "MINI_BATCH_SIZE = 250\r\n",
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].tolist()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "mlflow.tensorflow.autolog()\r\n",
    "mlflow.set_experiment(\"Deep Speech\")\r\n",
    "train(audio_gen, input_to_softmax=deep_speech_4, model_name=MODEL_NAME, epochs=EPOCHS, minibatch_size=MINI_BATCH_SIZE)\r\n",
    "\r\n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "D:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021/08/11 09:33:59 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'c2f046e1474e42f393191a26d3bc72b4', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": "2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[250,250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/rnn_3/while/body/_452/model_1/rnn_3/while/gru_cell_2/ones_like}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[model_1/ctc/Log/_380]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[250,250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/rnn_3/while/body/_452/model_1/rnn_3/while/gru_cell_2/ones_like}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_10485]\n\nFunction call stack:\ntrain_function -> train_function\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9a47717ecb84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautolog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Deep Speech\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_to_softmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep_speech_4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_NAME\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMINI_BATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\same\\Documents\\10Acadamy\\Week 4\\System\\Week-4\\scripts\\Train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(audio_gen, input_to_softmax, model_name, minibatch_size, optimizer, epochs, verbose)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     hist = model.fit_generator(generator=audio_gen.next_train(), steps_per_epoch=steps_per_epoch,\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maudio_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_valid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m          verbose=verbose)\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1941\u001b[0m                   \u001b[1;34m'will be removed in a future version. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1942\u001b[0m                   'Please use `Model.fit`, which supports generators.')\n\u001b[1;32m-> 1943\u001b[1;33m     return self.fit(\n\u001b[0m\u001b[0;32m   1944\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1945\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36msafe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mpatch_is_class\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m                         \u001b[0mpatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_original\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    165\u001b[0m                 \u001b[1;31m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# the original implementation exception once the callback completes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_patch_implementation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanaged_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtry_mlflow_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_managed_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 result = super(PatchWithManagedRun, self)._patch_implementation(\n\u001b[0m\u001b[0;32m    219\u001b[0m                     \u001b[0moriginal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\tensorflow.py\u001b[0m in \u001b[0;36m_patch_implementation\u001b[1;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1095\u001b[0m                 \u001b[0m_log_early_stop_callback_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mearly_stop_callback\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1097\u001b[1;33m                 \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1098\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m                 \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py\u001b[0m in \u001b[0;36mcall_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    446\u001b[0m                                 \u001b[0mdisable_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreroute_warnings\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                             ):\n\u001b[1;32m--> 448\u001b[1;33m                                 \u001b[0moriginal_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moriginal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mog_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mog_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                             try_log_autologging_event(\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    948\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 950\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    951\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\same\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: 2 root error(s) found.\n  (0) Resource exhausted:  OOM when allocating tensor with shape[250,250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/rnn_3/while/body/_452/model_1/rnn_3/while/gru_cell_2/ones_like}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[model_1/ctc/Log/_380]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n  (1) Resource exhausted:  OOM when allocating tensor with shape[250,250] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/rnn_3/while/body/_452/model_1/rnn_3/while/gru_cell_2/ones_like}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_10485]\n\nFunction call stack:\ntrain_function -> train_function\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}