{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import os,sys\r\n",
    "import pandas as pd\r\n",
    "import pickle\r\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\r\n",
    "from wer import calculate_wer\r\n",
    "\r\n",
    "from Models import cnn_rnn_model,simple_rnn,model_2,bidirectional_rnn_model_gpu,bidirectional_rnn_model\r\n",
    "from Batch import Batch\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "data=pd.read_json('../artifacts/meta.json')\r\n",
    "data.drop(data[data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/features.pkl','rb') as tel:\r\n",
    "    features=pickle.load(tel)\r\n",
    "    tel.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "valid_data=pd.read_json(\"../artifacts/valid_meta.json\")\r\n",
    "valid_data.drop(valid_data[valid_data[\"text\"].str.contains(\"\"\"[!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~1234567890]\"\"\", na=False)].index,inplace=True)\r\n",
    "with open('../artifacts/valid_features.pkl','rb') as val:\r\n",
    "    valid_features=pickle.load(val)\r\n",
    "    val.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "FEATURES_LIST=features\r\n",
    "\r\n",
    "TEXT_LIST=data[\"text\"].to_numpy()\r\n",
    "\r\n",
    "FEATURES_VALID_LIST=valid_features\r\n",
    "\r\n",
    "TEXT_VALID_LIST=valid_data[\"text\"].to_numpy()\r\n",
    "MINI_BATCH_SIZE=250\r\n",
    "\r\n",
    "\r\n",
    "audio_gen = Batch(FEATURES_LIST,FEATURES_VALID_LIST,TEXT_LIST,TEXT_VALID_LIST,MINI_BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "bidirectional_rnn=bidirectional_rnn_model_gpu(input_dim=26, \r\n",
    "                        units=250)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 500)         417000    \n",
      "_________________________________________________________________\n",
      "norm_bidir_rnn (BatchNormali (None, None, 500)         2000      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, None, 29)          14529     \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 433,529\n",
      "Trainable params: 432,529\n",
      "Non-trainable params: 1,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "cnn_rnn = cnn_rnn_model(input_dim=26, # change to 13 if you would like to use MFCC features\r\n",
    "                        filters=250,\r\n",
    "                        kernel_size=4, \r\n",
    "                        conv_stride=1,\r\n",
    "                        conv_border_mode='same',\r\n",
    "                        units=200,output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 250)         26250     \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "rnn (SimpleRNN)              (None, None, 200)         90200     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 29)          5829      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 124,079\n",
      "Trainable params: 123,179\n",
      "Non-trainable params: 900\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "deep_speech = model_2(input_dim=26,\r\n",
    "                filters=100,\r\n",
    "                kernel_size=4, \r\n",
    "                conv_stride=1,\r\n",
    "                conv_border_mode='valid',\r\n",
    "                units=250,\r\n",
    "                activation='tanh',\r\n",
    "                dropout_rate=0.2,\r\n",
    "                number_of_layers=2,\r\n",
    "                output_dim=29)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       [(None, None, 26)]        0         \n",
      "_________________________________________________________________\n",
      "layer_1_conv (Conv1D)        (None, None, 100)         10500     \n",
      "_________________________________________________________________\n",
      "conv_batch_norm (BatchNormal (None, None, 100)         400       \n",
      "_________________________________________________________________\n",
      "rnn_1 (GRU)                  (None, None, 250)         264000    \n",
      "_________________________________________________________________\n",
      "bt_rnn_1 (BatchNormalization (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "final_layer_of_rnn (GRU)     (None, None, 250)         376500    \n",
      "_________________________________________________________________\n",
      "bt_rnn_final (BatchNormaliza (None, None, 250)         1000      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 29)          7279      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, None, 29)          0         \n",
      "=================================================================\n",
      "Total params: 660,679\n",
      "Trainable params: 659,479\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with open('models\\\\bidirectional_rnn_gpu.h5', 'rb') as t:\r\n",
    "        bidirectional_rnn_model_hist=pickle.load( t)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "with open('models\\\\deep_speech.pickle', 'rb') as f:\r\n",
    "        deep_speech_hist=pickle.load( f)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "with open('models\\\\simple_rnn_model.pickle', 'rb') as g:\r\n",
    "        cnn_hist=pickle.load( g)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "cnn_rnn.load_weights('./model/cnn.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "deep_speech.load_weights('./model/deep.h5')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "from wer import predict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "predict(audio_gen,35,'validation',deep_speech)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Truth: familia za waliopoteza maisha nchini cambodia baada ya kukanyagana katika tamasha la kijadi\n",
      "Predicted: familiyatawliokodeza maisha njini kambodiabada a kukanya dala katikatamasha la idiali\n",
      "wer: 21\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "predict(audio_gen,35,'validation',cnn_rnn)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Truth: familia za waliopoteza maisha nchini cambodia baada ya kukanyagana katika tamasha la kijadi\n",
      "Predicted: kamila waliow deda mesha nchiniepambod a bada upana dalna katika tamashalakigaji\n",
      "wer: 28\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "predict(audio_gen,17,'validation',deep_speech)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "3ebe1e15dab481e38dbc50cacd21ed8ec6b22a54b0f3cb3b993bb569cf9c8bed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}